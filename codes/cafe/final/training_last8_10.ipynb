{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the input data\n",
      "(517085, 129, 16)\n",
      "H (517078, 8, 129, 16)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 123, 10)       25152     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 123, 10)       40        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 123, 10)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 119, 6)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 119, 6)       24        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 119, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 117, 4)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256, 117, 4)       16        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256, 117, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 256, 117, 4)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256, 117, 4)       16        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256, 117, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 128, 119, 6)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128, 119, 6)       24        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128, 119, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 123, 10)       204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64, 123, 10)       40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 123, 10)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 1, 129, 16)        3137      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1, 129, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1, 129, 16)        0         \n",
      "=================================================================\n",
      "Total params: 1,094,305\n",
      "Trainable params: 1,094,193\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 511907 samples, validate on 5171 samples\n",
      "Epoch 1/10\n",
      "511907/511907 [==============================] - 487s 951us/step - loss: 5.5381 - acc: 0.1372 - val_loss: 5.1203 - val_acc: 0.1403\n",
      "Epoch 2/10\n",
      "511907/511907 [==============================] - 483s 943us/step - loss: 5.4634 - acc: 0.1545 - val_loss: 5.0670 - val_acc: 0.1585\n",
      "Epoch 3/10\n",
      "511907/511907 [==============================] - 481s 939us/step - loss: 5.4337 - acc: 0.1663 - val_loss: 5.0886 - val_acc: 0.1660\n",
      "Epoch 4/10\n",
      "511907/511907 [==============================] - 517s 1ms/step - loss: 5.4199 - acc: 0.1741 - val_loss: 5.0567 - val_acc: 0.1572\n",
      "Epoch 5/10\n",
      "511907/511907 [==============================] - 570s 1ms/step - loss: 5.4107 - acc: 0.1798 - val_loss: 5.0401 - val_acc: 0.1746\n",
      "Epoch 6/10\n",
      "511907/511907 [==============================] - 542s 1ms/step - loss: 5.4040 - acc: 0.1844 - val_loss: 5.0342 - val_acc: 0.1831\n",
      "Epoch 7/10\n",
      "511907/511907 [==============================] - 524s 1ms/step - loss: 5.3980 - acc: 0.1880 - val_loss: 5.0267 - val_acc: 0.1781\n",
      "Epoch 8/10\n",
      "511907/511907 [==============================] - 571s 1ms/step - loss: 5.3935 - acc: 0.1910 - val_loss: 5.0263 - val_acc: 0.1828\n",
      "Epoch 9/10\n",
      "511907/511907 [==============================] - 573s 1ms/step - loss: 5.3898 - acc: 0.1938 - val_loss: 5.0207 - val_acc: 0.1827\n",
      "Epoch 10/10\n",
      "511907/511907 [==============================] - 575s 1ms/step - loss: 5.3858 - acc: 0.1965 - val_loss: 5.0230 - val_acc: 0.1922\n",
      "Got the input data\n",
      "(517085, 129, 16)\n",
      "H (517078, 8, 129, 16)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 64, 123, 10)       25152     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64, 123, 10)       40        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64, 123, 10)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 119, 6)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128, 119, 6)       24        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128, 119, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 256, 117, 4)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256, 117, 4)       16        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256, 117, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 117, 4)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256, 117, 4)       16        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256, 117, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 128, 119, 6)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 128, 119, 6)       24        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 128, 119, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 64, 123, 10)       204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 64, 123, 10)       40        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64, 123, 10)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 1, 129, 16)        3137      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1, 129, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1, 129, 16)        0         \n",
      "=================================================================\n",
      "Total params: 1,094,305\n",
      "Trainable params: 1,094,193\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 511907 samples, validate on 5171 samples\n",
      "Epoch 1/10\n",
      "511907/511907 [==============================] - 505s 987us/step - loss: 5.5526 - acc: 0.1351 - val_loss: 5.1089 - val_acc: 0.1465\n",
      "Epoch 2/10\n",
      "511907/511907 [==============================] - 475s 928us/step - loss: 5.4683 - acc: 0.1545 - val_loss: 5.0812 - val_acc: 0.1675\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511907/511907 [==============================] - 475s 927us/step - loss: 5.4360 - acc: 0.1636 - val_loss: 5.0516 - val_acc: 0.1684\n",
      "Epoch 4/10\n",
      "511907/511907 [==============================] - 476s 929us/step - loss: 5.4191 - acc: 0.1715 - val_loss: 5.0566 - val_acc: 0.1720\n",
      "Epoch 5/10\n",
      "511907/511907 [==============================] - 475s 928us/step - loss: 5.4083 - acc: 0.1771 - val_loss: 5.0391 - val_acc: 0.1746\n",
      "Epoch 6/10\n",
      "511907/511907 [==============================] - 475s 928us/step - loss: 5.4008 - acc: 0.1821 - val_loss: 5.0312 - val_acc: 0.1795\n",
      "Epoch 7/10\n",
      "511907/511907 [==============================] - 476s 930us/step - loss: 5.3953 - acc: 0.1860 - val_loss: 5.0407 - val_acc: 0.1785\n",
      "Epoch 8/10\n",
      "511907/511907 [==============================] - 475s 927us/step - loss: 5.3901 - acc: 0.1893 - val_loss: 5.0294 - val_acc: 0.1764\n",
      "Epoch 9/10\n",
      "511907/511907 [==============================] - 474s 927us/step - loss: 5.3861 - acc: 0.1921 - val_loss: 5.0224 - val_acc: 0.1885\n",
      "Epoch 10/10\n",
      "511907/511907 [==============================] - 474s 926us/step - loss: 5.3822 - acc: 0.1951 - val_loss: 5.0187 - val_acc: 0.1890\n"
     ]
    }
   ],
   "source": [
    "import pickle as pk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\"\n",
    "for d in ['/device:GPU:2', '/device:GPU:3']:\n",
    "  with tf.device(d):\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    #from keras.layers import Dense, Dropout, Flatten\n",
    "    from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose,Activation\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "    from keras import backend as K\n",
    "    epochs = 10\n",
    "    batch_size =64\n",
    "    pickle_train = open(\"noiseCafe_20.pickle\",\"rb\")\n",
    "    x_train = pk.load(pickle_train)\n",
    "    pickle_trainlabel = open(\"cleanCafe.pickle\",\"rb\")\n",
    "    y_train = pk.load(pickle_trainlabel)\n",
    "\n",
    "    print(\"Got the input data\")\n",
    "    #x_train = np.asarray(x_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    print(np.asarray(x_train).shape)\n",
    "    #     print(x_train[0:10].shape)\n",
    "    X_train = []\n",
    "    #X_train = np.asarray(X_train)\n",
    "    for i in range(7,len(x_train)):\n",
    "        X_train.append(x_train[i-7:i+1])\n",
    "    #     temp = x_train[i-7]\n",
    "    #     for j in range(1,8):\n",
    "    #         temp = np.concatenate((temp,x_train[(i-7)+j]),axis=1)\n",
    "    #     X_train.append(temp)\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    print(\"H\",np.asarray(X_train).shape)\n",
    "    # X_train = X_train.reshape(X_train.shape[0], 129, 128, 1)\n",
    "    # print(\"H2\",np.asarray(X_train).shape)\n",
    "    y_train = y_train.reshape(y_train.shape[0],1,129, 16)\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(7, 7),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\",input_shape=(8,129,16)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (5, 5),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (1, 1),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    #model.add(Conv2DTranspose(128, (3, 3), activation='relu',padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(128, (3, 3),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(64, (5, 5),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(1, (7, 7),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999),\n",
    "                  metrics=['accuracy'])\n",
    "    #model.build()\n",
    "    #     def ATH():\n",
    "    #         return 3.64*(pow(f/1000,0.8)) - 6.5*(np.exp(0.6*(pow(f/1000-3.3,2)))) + 0.001*(pow(f/1000,4))\n",
    "\n",
    "    #     def myloss(y_true,y_pred,weights):\n",
    "    #         return np.mean((weights(y_true-y_pred))**2)\n",
    "\n",
    "    print(model.summary())\n",
    "    model.fit(np.asarray(X_train), np.asarray(y_train[7:]),\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split = 0.01\n",
    "             )\n",
    "\n",
    "    model.save_weights('weights_8frames_10.h5')\n",
    "    model.save('model_8frames_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('model_8frames_30.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "sample_rate, samples = wavfile.read('/media/hd2/chaitanya/Deep_Learning/project/TCDTIMIT/Noisy_TCDTIMIT/Cafe/20/lipspeakers/Lipspkr2/straightcam/si1308.wav')\n",
    "print(sample_rate)\n",
    "print(len(samples))\n",
    "print(samples.shape)\n",
    "print((samples).shape)\n",
    "NoiseBabble= []\n",
    "Phase = []\n",
    "f, t, Zxx = signal.stft(samples, sample_rate,nperseg=256,nfft=256)\n",
    "print(\"Z\",Zxx.shape)\n",
    "phase = np.angle(Zxx)\n",
    "T = len(t)//16\n",
    "print(\"T\",T)\n",
    "for i in range(0,(T)*16,16):\n",
    "  NoiseBabble.append(np.log(np.abs(Zxx[:,i:i+16])+1e-8))\n",
    "  Phase.append(phase[:,i:i+16])\n",
    "print(\"N\",np.asarray(NoiseBabble).shape)\n",
    "X_NoiseBabble = []\n",
    "NoiseBabble = np.asarray(NoiseBabble)\n",
    "print(\"S\",NoiseBabble.shape)\n",
    "for i in range(0,7):\n",
    "    print(np.asarray(X_NoiseBabble).shape)\n",
    "    X_NoiseBabble.append(NoiseBabble[0:8])\n",
    "for i in range(7,len(NoiseBabble)):\n",
    "    X_NoiseBabble.append(NoiseBabble[i-7:i+1])\n",
    "print(\"H1\",np.asarray(X_NoiseBabble).shape)\n",
    "b = np.asarray(X_NoiseBabble)\n",
    "rectified = new_model.predict(b)\n",
    "print(rectified.shape)\n",
    "rectified =rectified.reshape(rectified.shape[0], 129, 16)\n",
    "print(rectified.shape)\n",
    "A = np.zeros((129,0))\n",
    "for i in range(T):\n",
    "  S = np.exp(rectified[i])\n",
    "  A = np.append(A,S*np.cos(Phase[i]) + 1j * S*np.sin(Phase[i]),axis=1)\n",
    "t,x = signal.istft(A,nperseg=256,nfft=256)\n",
    "x = np.asarray(x, dtype=np.int16)\n",
    "#print(len(x))\n",
    "#data=np.int16(x/np.max(np.abs(x)) * 32767)\n",
    "wavfile.write('/media/hd2/chaitanya/Deep_Learning/project/TCDTIMIT/code/cafe/testing/frames_si1021.wav', 16000, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
