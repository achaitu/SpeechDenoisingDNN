{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\"\n",
    "for d in ['/device:GPU:2', '/device:GPU:3']:\n",
    "  with tf.device(d):\n",
    "    import keras\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(tf.Session(config=config))\n",
    "    \n",
    "    from keras.models import Sequential\n",
    "    #from keras.layers import Dense, Dropout, Flatten\n",
    "    from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose,Activation\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "    from keras import backend as K\n",
    "    epochs = 10\n",
    "    batch_size = 64\n",
    "    pickle_train = open(\"../noiseBabble_20db.pickle\",\"rb\")\n",
    "    x_train = pk.load(pickle_train)\n",
    "    pickle_trainlabel = open(\"../cleanBabble.pickle\",\"rb\")\n",
    "    y_train = pk.load(pickle_trainlabel)\n",
    "\n",
    "    print(\"Got the input data\")\n",
    "    #x_train = np.asarray(x_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    print(np.asarray(x_train).shape)\n",
    "    #     print(x_train[0:10].shape)\n",
    "    X_train = []\n",
    "    #X_train = np.asarray(X_train)\n",
    "    for i in range(7,len(x_train)):\n",
    "        X_train.append(x_train[i-7:i+1])\n",
    "    #     temp = x_train[i-7]\n",
    "    #     for j in range(1,8):\n",
    "    #         temp = np.concatenate((temp,x_train[(i-7)+j]),axis=1)\n",
    "    #     X_train.append(temp)\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    print(\"H\",np.asarray(X_train).shape)\n",
    "    # X_train = X_train.reshape(X_train.shape[0], 129, 128, 1)\n",
    "    # print(\"H2\",np.asarray(X_train).shape)\n",
    "    y_train = y_train.reshape(y_train.shape[0],1,129, 16)\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(7, 7),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\",input_shape=(8,129,16)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (5, 5),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (1, 1),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    #model.add(Conv2DTranspose(128, (3, 3), activation='relu',padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(128, (3, 3),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(64, (5, 5),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(1, (7, 7),padding='valid',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros',data_format= \"channels_first\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999),\n",
    "                  metrics=['accuracy'])\n",
    "    #model.build()\n",
    "    #     def ATH():\n",
    "    #         return 3.64*(pow(f/1000,0.8)) - 6.5*(np.exp(0.6*(pow(f/1000-3.3,2)))) + 0.001*(pow(f/1000,4))\n",
    "\n",
    "    #     def myloss(y_true,y_pred,weights):\n",
    "    #         return np.mean((weights(y_true-y_pred))**2)\n",
    "\n",
    "    print(model.summary())\n",
    "    with tf.device('/device:GPU:2') as open:\n",
    "        model.fit(np.asarray(X_train), np.asarray(y_train[7:]),\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_split = 0.01\n",
    "                 )\n",
    "\n",
    "    model.save_weights('weights_8frames_10_final.h5')\n",
    "    model.save('model_8frames_10_final.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
